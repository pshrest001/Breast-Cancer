{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breast Cancer \n",
    "# Praveena Shrestha \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract\n",
    "\n",
    "For Assignment 3, I have chosen dataset of one of the most common yet serious issue in United States i.e. \"Breast Cancer\". I have chosen the dataset of Breast Cancer Wisconsin Data Set from kaggle where it has data of characteristics of the cell nuclei present, mass present with their radii and perimeter of several number of patients of Wisconsin. The reason I chose the dataset is because lot of people are still loosing their life because it was too late to treat and did not notice about the symptoms. Breast Cancer is the second most common cancer worldwide amongst females mainly rather than males. Statistics show that 1 in 8 U.S. women will develop invasive breast cancer over her lifetime, while male breast cancer is very rare, such that less than one percent of all breast cancer cases develop in men and one in a thousand will ever be diagnosed. According to the listed survival rates, it decreases ever so greatly starting from Stage 0 or 1 (100%), Stage 2 (93%), Stage 3 (72%), to Stage 4 (22%).\n",
    "\n",
    "I am planning to use \"Support Vector Mechanism\" classification algorithm as it helps for datas with high number of features and able to show the prediction. By using Machine Learning algorithms, hopefully i will be able to find the connection between most of datas present and find the predictions if the patient can have breast cancer in future or not in very early stage. \n",
    "\n",
    "The dataset I have chosen is Breast Cancer Wisconsin Diagnostic Data Set and it is helpful to predict if the cancer is benign ( which does not invade your body) or malignant (which spreads around the body) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #Section 1 : Prepping the Regression datasets \n",
    "\n",
    "#### Dataset Information \n",
    "\n",
    "The dataset Breast Cancer Wisconsin Data Set has a comprehensive record of over 500 patients who has two kinds of breast cancer. It has total 32 columns which are further listed below: \n",
    "\n",
    "    1) ID number [ will not be using in regression] \n",
    "    2) Diagnosis (M = malignant, B = benign) \n",
    "    3) radius (mean of distances from center to points on perimeter) \n",
    "    4) texture (standard deviation of gray-scale values) \n",
    "    5) perimeter (mean of perimeter)\n",
    "    6) area (mean of area)\n",
    "    7) Mean of smoothness (local variation in radius lengths) \n",
    "    8) Mean of compactness (perimeter^2 / area - 1.0) \n",
    "    9) Mean of concavity (severity of concave portions of the contour) \n",
    "    10)Mean of concave points (number of concave portions of the contour) \n",
    "    11)Mean of symmetry \n",
    "    12)Mean of fractal dimension (\"coastline approximation\" - 1)\n",
    "    13) Standard error of radius \n",
    "    14) Standard error of texture \n",
    "    15) Standard error of perimeter\n",
    "    16) Standard error of area\n",
    "    17) Standard error of smoothness\n",
    "    18) Standard error of compactness\n",
    "    19) Standard error of concavity \n",
    "    20) Standard error of concave points \n",
    "    21) Standard error of symmetry \n",
    "    22) Standard error of fractal dimension\n",
    "    23) Worst of radius \n",
    "    24) Worst of texture\n",
    "    25) Worst of perimeter\n",
    "    26) Worst of area\n",
    "    27) Worst of smoothness\n",
    "    28) Worst of compactness\n",
    "    29) Worst of concavity \n",
    "    30) Worst of concave points\n",
    "    31) Worst of symmetry \n",
    "    32) Worst of fractal dimension\n",
    "Where other columns which stands for se = standard error and worst radius are the mean of 3 largest values of the radius, compactness, smoothness and perimeter. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.26540</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.18600</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.24300</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.25750</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.16250</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>843786</td>\n",
       "      <td>M</td>\n",
       "      <td>12.45</td>\n",
       "      <td>15.70</td>\n",
       "      <td>82.57</td>\n",
       "      <td>477.1</td>\n",
       "      <td>0.12780</td>\n",
       "      <td>0.17000</td>\n",
       "      <td>0.15780</td>\n",
       "      <td>0.08089</td>\n",
       "      <td>...</td>\n",
       "      <td>23.75</td>\n",
       "      <td>103.40</td>\n",
       "      <td>741.6</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>0.5249</td>\n",
       "      <td>0.5355</td>\n",
       "      <td>0.17410</td>\n",
       "      <td>0.3985</td>\n",
       "      <td>0.12440</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>844359</td>\n",
       "      <td>M</td>\n",
       "      <td>18.25</td>\n",
       "      <td>19.98</td>\n",
       "      <td>119.60</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>0.09463</td>\n",
       "      <td>0.10900</td>\n",
       "      <td>0.11270</td>\n",
       "      <td>0.07400</td>\n",
       "      <td>...</td>\n",
       "      <td>27.66</td>\n",
       "      <td>153.20</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.3784</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.3063</td>\n",
       "      <td>0.08368</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>84458202</td>\n",
       "      <td>M</td>\n",
       "      <td>13.71</td>\n",
       "      <td>20.83</td>\n",
       "      <td>90.20</td>\n",
       "      <td>577.9</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.16450</td>\n",
       "      <td>0.09366</td>\n",
       "      <td>0.05985</td>\n",
       "      <td>...</td>\n",
       "      <td>28.14</td>\n",
       "      <td>110.60</td>\n",
       "      <td>897.0</td>\n",
       "      <td>0.1654</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>0.2678</td>\n",
       "      <td>0.15560</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>0.11510</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>844981</td>\n",
       "      <td>M</td>\n",
       "      <td>13.00</td>\n",
       "      <td>21.82</td>\n",
       "      <td>87.50</td>\n",
       "      <td>519.8</td>\n",
       "      <td>0.12730</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.18590</td>\n",
       "      <td>0.09353</td>\n",
       "      <td>...</td>\n",
       "      <td>30.73</td>\n",
       "      <td>106.20</td>\n",
       "      <td>739.3</td>\n",
       "      <td>0.1703</td>\n",
       "      <td>0.5401</td>\n",
       "      <td>0.5390</td>\n",
       "      <td>0.20600</td>\n",
       "      <td>0.4378</td>\n",
       "      <td>0.10720</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>84501001</td>\n",
       "      <td>M</td>\n",
       "      <td>12.46</td>\n",
       "      <td>24.04</td>\n",
       "      <td>83.97</td>\n",
       "      <td>475.9</td>\n",
       "      <td>0.11860</td>\n",
       "      <td>0.23960</td>\n",
       "      <td>0.22730</td>\n",
       "      <td>0.08543</td>\n",
       "      <td>...</td>\n",
       "      <td>40.68</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.4</td>\n",
       "      <td>0.1853</td>\n",
       "      <td>1.0580</td>\n",
       "      <td>1.1050</td>\n",
       "      <td>0.22100</td>\n",
       "      <td>0.4366</td>\n",
       "      <td>0.20750</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>845636</td>\n",
       "      <td>M</td>\n",
       "      <td>16.02</td>\n",
       "      <td>23.24</td>\n",
       "      <td>102.70</td>\n",
       "      <td>797.8</td>\n",
       "      <td>0.08206</td>\n",
       "      <td>0.06669</td>\n",
       "      <td>0.03299</td>\n",
       "      <td>0.03323</td>\n",
       "      <td>...</td>\n",
       "      <td>33.88</td>\n",
       "      <td>123.80</td>\n",
       "      <td>1150.0</td>\n",
       "      <td>0.1181</td>\n",
       "      <td>0.1551</td>\n",
       "      <td>0.1459</td>\n",
       "      <td>0.09975</td>\n",
       "      <td>0.2948</td>\n",
       "      <td>0.08452</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>84610002</td>\n",
       "      <td>M</td>\n",
       "      <td>15.78</td>\n",
       "      <td>17.89</td>\n",
       "      <td>103.60</td>\n",
       "      <td>781.0</td>\n",
       "      <td>0.09710</td>\n",
       "      <td>0.12920</td>\n",
       "      <td>0.09954</td>\n",
       "      <td>0.06606</td>\n",
       "      <td>...</td>\n",
       "      <td>27.28</td>\n",
       "      <td>136.50</td>\n",
       "      <td>1299.0</td>\n",
       "      <td>0.1396</td>\n",
       "      <td>0.5609</td>\n",
       "      <td>0.3965</td>\n",
       "      <td>0.18100</td>\n",
       "      <td>0.3792</td>\n",
       "      <td>0.10480</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>846226</td>\n",
       "      <td>M</td>\n",
       "      <td>19.17</td>\n",
       "      <td>24.80</td>\n",
       "      <td>132.40</td>\n",
       "      <td>1123.0</td>\n",
       "      <td>0.09740</td>\n",
       "      <td>0.24580</td>\n",
       "      <td>0.20650</td>\n",
       "      <td>0.11180</td>\n",
       "      <td>...</td>\n",
       "      <td>29.94</td>\n",
       "      <td>151.70</td>\n",
       "      <td>1332.0</td>\n",
       "      <td>0.1037</td>\n",
       "      <td>0.3903</td>\n",
       "      <td>0.3639</td>\n",
       "      <td>0.17670</td>\n",
       "      <td>0.3176</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>846381</td>\n",
       "      <td>M</td>\n",
       "      <td>15.85</td>\n",
       "      <td>23.95</td>\n",
       "      <td>103.70</td>\n",
       "      <td>782.7</td>\n",
       "      <td>0.08401</td>\n",
       "      <td>0.10020</td>\n",
       "      <td>0.09938</td>\n",
       "      <td>0.05364</td>\n",
       "      <td>...</td>\n",
       "      <td>27.66</td>\n",
       "      <td>112.00</td>\n",
       "      <td>876.5</td>\n",
       "      <td>0.1131</td>\n",
       "      <td>0.1924</td>\n",
       "      <td>0.2322</td>\n",
       "      <td>0.11190</td>\n",
       "      <td>0.2809</td>\n",
       "      <td>0.06287</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>84667401</td>\n",
       "      <td>M</td>\n",
       "      <td>13.73</td>\n",
       "      <td>22.61</td>\n",
       "      <td>93.60</td>\n",
       "      <td>578.3</td>\n",
       "      <td>0.11310</td>\n",
       "      <td>0.22930</td>\n",
       "      <td>0.21280</td>\n",
       "      <td>0.08025</td>\n",
       "      <td>...</td>\n",
       "      <td>32.01</td>\n",
       "      <td>108.80</td>\n",
       "      <td>697.7</td>\n",
       "      <td>0.1651</td>\n",
       "      <td>0.7725</td>\n",
       "      <td>0.6943</td>\n",
       "      <td>0.22080</td>\n",
       "      <td>0.3596</td>\n",
       "      <td>0.14310</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0     842302         M        17.99         10.38          122.80     1001.0   \n",
       "1     842517         M        20.57         17.77          132.90     1326.0   \n",
       "2   84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3   84348301         M        11.42         20.38           77.58      386.1   \n",
       "4   84358402         M        20.29         14.34          135.10     1297.0   \n",
       "5     843786         M        12.45         15.70           82.57      477.1   \n",
       "6     844359         M        18.25         19.98          119.60     1040.0   \n",
       "7   84458202         M        13.71         20.83           90.20      577.9   \n",
       "8     844981         M        13.00         21.82           87.50      519.8   \n",
       "9   84501001         M        12.46         24.04           83.97      475.9   \n",
       "10    845636         M        16.02         23.24          102.70      797.8   \n",
       "11  84610002         M        15.78         17.89          103.60      781.0   \n",
       "12    846226         M        19.17         24.80          132.40     1123.0   \n",
       "13    846381         M        15.85         23.95          103.70      782.7   \n",
       "14  84667401         M        13.73         22.61           93.60      578.3   \n",
       "\n",
       "    smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0           0.11840           0.27760         0.30010              0.14710   \n",
       "1           0.08474           0.07864         0.08690              0.07017   \n",
       "2           0.10960           0.15990         0.19740              0.12790   \n",
       "3           0.14250           0.28390         0.24140              0.10520   \n",
       "4           0.10030           0.13280         0.19800              0.10430   \n",
       "5           0.12780           0.17000         0.15780              0.08089   \n",
       "6           0.09463           0.10900         0.11270              0.07400   \n",
       "7           0.11890           0.16450         0.09366              0.05985   \n",
       "8           0.12730           0.19320         0.18590              0.09353   \n",
       "9           0.11860           0.23960         0.22730              0.08543   \n",
       "10          0.08206           0.06669         0.03299              0.03323   \n",
       "11          0.09710           0.12920         0.09954              0.06606   \n",
       "12          0.09740           0.24580         0.20650              0.11180   \n",
       "13          0.08401           0.10020         0.09938              0.05364   \n",
       "14          0.11310           0.22930         0.21280              0.08025   \n",
       "\n",
       "    ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0   ...          17.33           184.60      2019.0            0.1622   \n",
       "1   ...          23.41           158.80      1956.0            0.1238   \n",
       "2   ...          25.53           152.50      1709.0            0.1444   \n",
       "3   ...          26.50            98.87       567.7            0.2098   \n",
       "4   ...          16.67           152.20      1575.0            0.1374   \n",
       "5   ...          23.75           103.40       741.6            0.1791   \n",
       "6   ...          27.66           153.20      1606.0            0.1442   \n",
       "7   ...          28.14           110.60       897.0            0.1654   \n",
       "8   ...          30.73           106.20       739.3            0.1703   \n",
       "9   ...          40.68            97.65       711.4            0.1853   \n",
       "10  ...          33.88           123.80      1150.0            0.1181   \n",
       "11  ...          27.28           136.50      1299.0            0.1396   \n",
       "12  ...          29.94           151.70      1332.0            0.1037   \n",
       "13  ...          27.66           112.00       876.5            0.1131   \n",
       "14  ...          32.01           108.80       697.7            0.1651   \n",
       "\n",
       "    compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0              0.6656           0.7119               0.26540          0.4601   \n",
       "1              0.1866           0.2416               0.18600          0.2750   \n",
       "2              0.4245           0.4504               0.24300          0.3613   \n",
       "3              0.8663           0.6869               0.25750          0.6638   \n",
       "4              0.2050           0.4000               0.16250          0.2364   \n",
       "5              0.5249           0.5355               0.17410          0.3985   \n",
       "6              0.2576           0.3784               0.19320          0.3063   \n",
       "7              0.3682           0.2678               0.15560          0.3196   \n",
       "8              0.5401           0.5390               0.20600          0.4378   \n",
       "9              1.0580           1.1050               0.22100          0.4366   \n",
       "10             0.1551           0.1459               0.09975          0.2948   \n",
       "11             0.5609           0.3965               0.18100          0.3792   \n",
       "12             0.3903           0.3639               0.17670          0.3176   \n",
       "13             0.1924           0.2322               0.11190          0.2809   \n",
       "14             0.7725           0.6943               0.22080          0.3596   \n",
       "\n",
       "    fractal_dimension_worst  Unnamed: 32  \n",
       "0                   0.11890          NaN  \n",
       "1                   0.08902          NaN  \n",
       "2                   0.08758          NaN  \n",
       "3                   0.17300          NaN  \n",
       "4                   0.07678          NaN  \n",
       "5                   0.12440          NaN  \n",
       "6                   0.08368          NaN  \n",
       "7                   0.11510          NaN  \n",
       "8                   0.10720          NaN  \n",
       "9                   0.20750          NaN  \n",
       "10                  0.08452          NaN  \n",
       "11                  0.10480          NaN  \n",
       "12                  0.10230          NaN  \n",
       "13                  0.06287          NaN  \n",
       "14                  0.14310          NaN  \n",
       "\n",
       "[15 rows x 33 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas  #Import pandas to load the dataset \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pandas.read_csv('/Users/praveenathegreat/Downloads/data.csv')\n",
    "#Using the pandas to load data from source and storing inside the dataframe df  \n",
    "\n",
    "df.head(15) #gives the result of first 15 rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x118b99bd0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns \n",
    "#To see how many do have cancer \n",
    "\n",
    "sns.countplot(df['diagnosis'])\n",
    "\n",
    "#Where B is benign and M is malignant cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CLEANING THE DATAS \n",
    "\n",
    "#Replacing the B (benign) as 0 annd M (malignant) as 1 for convenience \n",
    "df[\"diagnosis\"] = df[\"diagnosis\"].replace(\"B\", 0)\n",
    "df[\"diagnosis\"] = df[\"diagnosis\"].replace(\"M\", 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>842302</td>\n",
       "      <td>1</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>842517</td>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>84300903</td>\n",
       "      <td>1</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>84348301</td>\n",
       "      <td>1</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>84358402</td>\n",
       "      <td>1</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302          1        17.99         10.38          122.80     1001.0   \n",
       "1    842517          1        20.57         17.77          132.90     1326.0   \n",
       "2  84300903          1        19.69         21.25          130.00     1203.0   \n",
       "3  84348301          1        11.42         20.38           77.58      386.1   \n",
       "4  84358402          1        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head() # checking the datas if they are replaced with values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                           0\n",
       "diagnosis                    0\n",
       "radius_mean                  0\n",
       "texture_mean                 0\n",
       "perimeter_mean               0\n",
       "area_mean                    0\n",
       "smoothness_mean              0\n",
       "compactness_mean             0\n",
       "concavity_mean               0\n",
       "concave points_mean          0\n",
       "symmetry_mean                0\n",
       "fractal_dimension_mean       0\n",
       "radius_se                    0\n",
       "texture_se                   0\n",
       "perimeter_se                 0\n",
       "area_se                      0\n",
       "smoothness_se                0\n",
       "compactness_se               0\n",
       "concavity_se                 0\n",
       "concave points_se            0\n",
       "symmetry_se                  0\n",
       "fractal_dimension_se         0\n",
       "radius_worst                 0\n",
       "texture_worst                0\n",
       "perimeter_worst              0\n",
       "area_worst                   0\n",
       "smoothness_worst             0\n",
       "compactness_worst            0\n",
       "concavity_worst              0\n",
       "concave points_worst         0\n",
       "symmetry_worst               0\n",
       "fractal_dimension_worst      0\n",
       "Unnamed: 32                569\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To find if there are any null values in the datas \n",
    "\n",
    "df.isnull().sum()\n",
    "\n",
    "#There are 569 Unnamed datas which will be dropped \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop id since they do not have any relation with the datas \n",
    "# Drop all the unnamed datas to clean the dataset \n",
    "\n",
    "df.drop([\"id\", \"Unnamed: 32\"],axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diagnosis                  0\n",
       "radius_mean                0\n",
       "texture_mean               0\n",
       "perimeter_mean             0\n",
       "area_mean                  0\n",
       "smoothness_mean            0\n",
       "compactness_mean           0\n",
       "concavity_mean             0\n",
       "concave points_mean        0\n",
       "symmetry_mean              0\n",
       "fractal_dimension_mean     0\n",
       "radius_se                  0\n",
       "texture_se                 0\n",
       "perimeter_se               0\n",
       "area_se                    0\n",
       "smoothness_se              0\n",
       "compactness_se             0\n",
       "concavity_se               0\n",
       "concave points_se          0\n",
       "symmetry_se                0\n",
       "fractal_dimension_se       0\n",
       "radius_worst               0\n",
       "texture_worst              0\n",
       "perimeter_worst            0\n",
       "area_worst                 0\n",
       "smoothness_worst           0\n",
       "compactness_worst          0\n",
       "concavity_worst            0\n",
       "concave points_worst       0\n",
       "symmetry_worst             0\n",
       "fractal_dimension_worst    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To check if there are any more null or unnamed datas in the dataframe\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2 Regression \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Datas:     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
      "0        17.99         10.38           122.8     1001.0          0.11840   \n",
      "1        20.57         17.77           132.9     1326.0          0.08474   \n",
      "\n",
      "   compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
      "0           0.27760          0.3001              0.14710         0.2419   \n",
      "1           0.07864          0.0869              0.07017         0.1812   \n",
      "\n",
      "   fractal_dimension_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
      "0                 0.07871  ...         25.38          17.33            184.6   \n",
      "1                 0.05667  ...         24.99          23.41            158.8   \n",
      "\n",
      "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
      "0      2019.0            0.1622             0.6656           0.7119   \n",
      "1      1956.0            0.1238             0.1866           0.2416   \n",
      "\n",
      "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
      "0                0.2654          0.4601                  0.11890  \n",
      "1                0.1860          0.2750                  0.08902  \n",
      "\n",
      "[2 rows x 30 columns] \n",
      "\n",
      "Testing:  0      1\n",
      "1      1\n",
      "2      1\n",
      "3      1\n",
      "4      1\n",
      "      ..\n",
      "564    1\n",
      "565    1\n",
      "566    1\n",
      "567    1\n",
      "568    0\n",
      "Name: diagnosis, Length: 569, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "# import train_test_split from sklearn model selection to split \n",
    "# dataframe into training and test set \n",
    "\n",
    "import numpy as np     #linear algebra \n",
    "import seaborn as sns \n",
    "\n",
    "#Using sklearn to split the datset \n",
    "\n",
    "train= df.drop('diagnosis', axis=1) #independent\n",
    "test_diag = df.diagnosis #dependent since cancer type is dependent in all other column\n",
    "\n",
    "# Prints the first two training datas and testing datas to check what are going to be trained and tested\n",
    "print(\"Training Datas: \", (train.iloc[0:2]), \"\\n\\nTesting: \", test_diag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X-Training Set:       radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
      "149        13.74         17.91           88.12      585.0          0.07944   \n",
      "124        13.37         16.39           86.10      553.5          0.07115   \n",
      "\n",
      "     compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
      "149           0.06376         0.02881              0.01329         0.1473   \n",
      "124           0.07325         0.08092              0.02800         0.1422   \n",
      "\n",
      "     fractal_dimension_mean  ...  radius_worst  texture_worst  \\\n",
      "149                 0.05580  ...         15.34          22.46   \n",
      "124                 0.05823  ...         14.26          22.75   \n",
      "\n",
      "     perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n",
      "149            97.19       725.9           0.09711             0.1824   \n",
      "124            91.99       632.1           0.10250             0.2531   \n",
      "\n",
      "     concavity_worst  concave points_worst  symmetry_worst  \\\n",
      "149           0.1564               0.06019          0.2350   \n",
      "124           0.3308               0.08978          0.2048   \n",
      "\n",
      "     fractal_dimension_worst  \n",
      "149                  0.07014  \n",
      "124                  0.07628  \n",
      "\n",
      "[2 rows x 30 columns] \n",
      "\n",
      " Y-Training Set:  149    0\n",
      "124    0\n",
      "Name: diagnosis, dtype: int64\n",
      "\n",
      " X- Testing Set:       radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
      "204        12.47         18.60           81.09      481.9          0.09965   \n",
      "70         18.94         21.31          123.60     1130.0          0.09009   \n",
      "\n",
      "     compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
      "204            0.1058         0.08005              0.03821         0.1925   \n",
      "70             0.1029         0.10800              0.07951         0.1582   \n",
      "\n",
      "     fractal_dimension_mean  ...  radius_worst  texture_worst  \\\n",
      "204                 0.06373  ...         14.97          24.64   \n",
      "70                  0.05461  ...         24.86          26.58   \n",
      "\n",
      "     perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n",
      "204            96.05       677.9            0.1426             0.2378   \n",
      "70            165.90      1866.0            0.1193             0.2336   \n",
      "\n",
      "     concavity_worst  concave points_worst  symmetry_worst  \\\n",
      "204           0.2671                0.1015          0.3014   \n",
      "70            0.2687                0.1789          0.2551   \n",
      "\n",
      "     fractal_dimension_worst  \n",
      "204                  0.08750  \n",
      "70                   0.06589  \n",
      "\n",
      "[2 rows x 30 columns] \n",
      "\n",
      " Y Testing Set:  204    0\n",
      "70     1\n",
      "Name: diagnosis, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Building the matrice \n",
    "#Split the data train 70% and test 20% to validate the model later\n",
    "\n",
    "X_trainingset, X_testingset, Y_trainingset, Y_testingset = train_test_split(train, test_diag, test_size=0.3, random_state=42)\n",
    "\n",
    "# Displaying first two rows of training and testing sets of X and Y \n",
    "print(\"\\nX-Training Set: \", X_trainingset.iloc[0:2], \"\\n\\n Y-Training Set: \", Y_trainingset.iloc[0:2])\n",
    "print(\"\\n X- Testing Set: \", X_testingset.iloc[0:2], \"\\n\\n Y Testing Set: \", Y_testingset.iloc[0:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "from sklearn import linear_model \n",
    "import sklearn.linear_model as skl_lm\n",
    "\n",
    "reg = linear_model.LinearRegression() \n",
    "#Using the linear model from Linear Regression to fit the datas \n",
    "reg.fit(X_trainingset,Y_trainingset)\n",
    "lm = skl_lm.LinearRegression()\n",
    "model = lm.fit(X_trainingset,Y_trainingset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.37372577e-01, -7.79428357e-03,  1.82105707e-02,  9.78666191e-05,\n",
       "        1.90315420e+00, -5.26086706e+00,  3.35439139e-01,  6.69106766e+00,\n",
       "       -3.21568985e-01,  4.27164704e+00,  4.61122438e-01, -7.97442502e-02,\n",
       "        3.75583740e-03, -1.66070766e-03,  2.38396965e+01, -2.29146524e+00,\n",
       "       -4.20544140e+00,  1.97044602e+01, -1.78524925e+00,  9.75990317e-01,\n",
       "        1.81809089e-01,  2.03391654e-02, -7.82072632e-03, -8.10744800e-04,\n",
       "       -1.29891730e+00,  8.91398060e-01,  8.93861181e-01, -2.23179043e+00,\n",
       "        1.02916501e+00,  8.55319728e-01])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.coef_ #Coefficients needed to find the best value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the values of testing set and compare with the actucal values first\n",
    "\n",
    "a= reg.predict(X_testingset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.740069958148645"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[2] #Predicted Value of X tetsing set at a[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_testingset[2] #Value of Y testing set \n",
    "#Value predicted and value we have for testing set are closer to each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Testing Set</th>\n",
       "      <th>Predicted Testing Set</th>\n",
       "      <th>Difference between Actual and Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0.363589</td>\n",
       "      <td>-0.363589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0.801068</td>\n",
       "      <td>0.198932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>131</td>\n",
       "      <td>1</td>\n",
       "      <td>0.740070</td>\n",
       "      <td>0.259930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>431</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.131227</td>\n",
       "      <td>0.131227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.128622</td>\n",
       "      <td>0.128622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>567</td>\n",
       "      <td>1</td>\n",
       "      <td>1.712865</td>\n",
       "      <td>-0.712865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>369</td>\n",
       "      <td>1</td>\n",
       "      <td>1.085145</td>\n",
       "      <td>-0.085145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0.596849</td>\n",
       "      <td>0.403151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>0.747238</td>\n",
       "      <td>-0.747238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>477</td>\n",
       "      <td>0</td>\n",
       "      <td>0.041638</td>\n",
       "      <td>-0.041638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Testing Set  Predicted Testing Set  \\\n",
       "204            0               0.363589   \n",
       "70             1               0.801068   \n",
       "131            1               0.740070   \n",
       "431            0              -0.131227   \n",
       "540            0              -0.128622   \n",
       "567            1               1.712865   \n",
       "369            1               1.085145   \n",
       "29             1               0.596849   \n",
       "81             0               0.747238   \n",
       "477            0               0.041638   \n",
       "\n",
       "     Difference between Actual and Predicted  \n",
       "204                                -0.363589  \n",
       "70                                  0.198932  \n",
       "131                                 0.259930  \n",
       "431                                 0.131227  \n",
       "540                                 0.128622  \n",
       "567                                -0.712865  \n",
       "369                                -0.085145  \n",
       "29                                  0.403151  \n",
       "81                                 -0.747238  \n",
       "477                                -0.041638  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import seaborn as sns \n",
    "\n",
    "# Showing first rows of actual testing set with predicted and computing the difference between two \n",
    "\n",
    "df = pd.DataFrame({'Testing Set': Y_testingset, 'Predicted Testing Set': a, 'Difference between Actual and Predicted':(Y_testingset-a)})\n",
    "\n",
    "#sns.swarmplot(x=\"Y_testingset\",y=\"predict_val\",hue='diagnosis', data=df)\n",
    "# We define a variable df1 to return the first 10 rows of the dataset\n",
    "dff = df.head(10)\n",
    "dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept:  [-5.02084858]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a1d1a72d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "from sklearn import linear_model\n",
    "from matplotlib import pyplot as plt\n",
    "import pylab\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "'''This graph will be plotted in respoect to radius of the mass present in the patient\n",
    "versus the perimeter (size of rhe core tumor) since there are only benign and malignant tissue therefore,\n",
    "could not shown in model below'''\n",
    "\n",
    "data_frame = pd.read_csv('/Users/praveenathegreat/Downloads/data.csv')\n",
    "#Selecting the original data_frame to create one variable forr X and another Y ar a time \n",
    "\n",
    "Xdata = data_frame['radius_mean'].values.reshape(-1,1) #reshape is used since array is expected but only one feature is provided\n",
    "Ydata = data_frame['perimeter_mean'].values.reshape(-1,1)\n",
    "#Using the same ratio as previous which was \n",
    "#Training set will be 80% and Testing set will be 20% \n",
    "\n",
    "#Using the sklearn.model selection to split the training and testing datasets\n",
    "X_anothertrain, X_anothertest, Y_anothertrain, Y_anothertest = train_test_split(Xdata, Ydata, test_size=0.2, random_state=42)\n",
    "\n",
    "#Creating instance again like above for fresh datasets \n",
    "reg2 = linear_model.LinearRegression()  \n",
    "reg2.fit(X_anothertrain, Y_anothertrain)\n",
    "\n",
    "# Intercept of the graph \n",
    "print(\"Intercept: \", reg2.intercept_)\n",
    "\n",
    "# Predict the values from linear regression \n",
    "predict_values = reg2.predict(X_anothertest)\n",
    "\n",
    "#Plotting the datas in the graph using matplotlib \n",
    "fig=plt.figure()\n",
    "ax=fig.add_axes([1,2.5,1.2,1])\n",
    "ax.scatter(X_anothertest, Y_anothertest, color='blue', label='Test')\n",
    "pylab.plot(X_anothertest, predict_values, color='black', linewidth=2, label='Predict')\n",
    "ax.set_title(\"Linear Regression Model\")\n",
    "ax.set_xlabel(\"Radius Mean \")\n",
    "ax.set_ylabel(\"Perimeter Mean\")\n",
    "ax.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error is:  0.20007348217357585\n",
      "Mean Squared Error is:  0.06728376859363198\n",
      "Root Mean Squared Error is:  0.25939114979819955\n",
      "\n",
      "Quadratic Mean Squared Error is:  0.08952338788629202\n"
     ]
    }
   ],
   "source": [
    "#Using linear regression model to calculate the accuracy and error rate of the test set \n",
    "\n",
    "from sklearn.metrics import mean_absolute_error #needed to find the mean absolute error\n",
    "from sklearn.metrics import mean_squared_error #needed to find mean squared error\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import sklearn.linear_model as skl_lm\n",
    "from sklearn import metrics\n",
    "\n",
    "#Linear Least Square Regression Validation \n",
    "mean_abs_error = mean_absolute_error(Y_testingset, a)\n",
    "mean_squared_error = mean_squared_error(Y_testingset, a)\n",
    "root_mean_squared_error = np.sqrt(metrics.mean_squared_error(Y_testingset, a))\n",
    "\n",
    "print(\"Mean Absolute Error is: \", mean_abs_error)\n",
    "print(\"Mean Squared Error is: \", mean_squared_error)\n",
    "print(\"Root Mean Squared Error is: \", root_mean_squared_error)\n",
    "\n",
    "'''Trying to figure out the difference between linear and quadratic validation set error rates'''\n",
    "#Quadratic Least Square Regression\n",
    "\n",
    "lm = skl_lm.LinearRegression()\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "Y_testingset2 = poly.fit_transform((Y_testingset.values.reshape(-1,1)))\n",
    "a2=poly.fit_transform((a.reshape(-1,1)))\n",
    "\n",
    "model = lm.fit(Y_testingset2, Y_testingset)\n",
    "print(\"\\nQuadratic Mean Squared Error is: \", metrics.mean_squared_error(Y_testingset, model.predict(a2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Linear Regression Mean Square Error is:  0.06728376859363198\n",
      "\n",
      "K-Fold Cross-Validation Mean Square Error is: 0.07031819984524679\n",
      "\n",
      "STD of K-Fold Cross Validation: 0.03679510334224456\n"
     ]
    }
   ],
   "source": [
    "# K_FOLD Cross Validation \n",
    "#initiaze a vector in which CV= Cross validation errors correcponding to the polynomial fits or orders one to ten \n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn import svm \n",
    "\n",
    "crossvalidation = KFold(n_splits=10, random_state=42) #chosong k=10 \n",
    "\n",
    "\n",
    "#Making new dataframe again and repeating same process as section 1 \n",
    "df2 = pd.read_csv('/Users/praveenathegreat/Downloads/data.csv')\n",
    "df2[\"diagnosis\"] = df2[\"diagnosis\"].replace(\"B\", 0)\n",
    "df2[\"diagnosis\"] = df2[\"diagnosis\"].replace(\"M\", 1)\n",
    "df2.drop(\"Unnamed: 32\" ,axis=1, inplace=True)\n",
    "X = df2.drop('diagnosis', axis=1)\n",
    "Y = df2.diagnosis\n",
    "\n",
    "train2= df2.drop('diagnosis', axis=1) #independent\n",
    "test_diag2 = df2.diagnosis #dependent since cancer type is dependent in all other column\n",
    "X_trainingset2, X_testingset2, Y_trainingset2, Y_testingset2 = train_test_split(train2, test_diag2, test_size=0.3, random_state=42)\n",
    "\n",
    "# split contains the dataset from above \n",
    "\n",
    "\n",
    "    #Xtrain, Xtest, Ytrain, Ytest = X.iloc[train_index], X.iloc[test_index], Y.iloc[train_index], Y.iloc[test_index]\n",
    "for i in range(1):\n",
    "    poly=PolynomialFeatures(degree=1) #linear \n",
    "    X_current = poly.fit_transform(train2)\n",
    "    model = lm.fit(X_current, test_diag2)\n",
    "    CVscores = cross_val_score(reg, X_current, test_diag2, scoring=\"neg_mean_squared_error\", cv = crossvalidation, n_jobs=1)\n",
    "    print(\"\\nLinear Regression Mean Square Error is: \", mean_squared_error)\n",
    "\n",
    "    print(\"\\nK-Fold Cross-Validation Mean Square Error is: \" + str(np.mean(np.abs(CVscores))) + \"\\n\\nSTD of K-Fold Cross Validation: \" + str(np.std(CVscores)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3 : Prepping the classification dataset \n",
    "### I will be using same Breast Cancer dataset as above "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>843786</td>\n",
       "      <td>M</td>\n",
       "      <td>12.45</td>\n",
       "      <td>15.70</td>\n",
       "      <td>82.57</td>\n",
       "      <td>477.1</td>\n",
       "      <td>0.12780</td>\n",
       "      <td>0.17000</td>\n",
       "      <td>0.1578</td>\n",
       "      <td>0.08089</td>\n",
       "      <td>...</td>\n",
       "      <td>23.75</td>\n",
       "      <td>103.40</td>\n",
       "      <td>741.6</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>0.5249</td>\n",
       "      <td>0.5355</td>\n",
       "      <td>0.1741</td>\n",
       "      <td>0.3985</td>\n",
       "      <td>0.12440</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>844359</td>\n",
       "      <td>M</td>\n",
       "      <td>18.25</td>\n",
       "      <td>19.98</td>\n",
       "      <td>119.60</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>0.09463</td>\n",
       "      <td>0.10900</td>\n",
       "      <td>0.1127</td>\n",
       "      <td>0.07400</td>\n",
       "      <td>...</td>\n",
       "      <td>27.66</td>\n",
       "      <td>153.20</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.3784</td>\n",
       "      <td>0.1932</td>\n",
       "      <td>0.3063</td>\n",
       "      <td>0.08368</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "5    843786         M        12.45         15.70           82.57      477.1   \n",
       "6    844359         M        18.25         19.98          119.60     1040.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "5          0.12780           0.17000          0.1578              0.08089   \n",
       "6          0.09463           0.10900          0.1127              0.07400   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "5  ...          23.75           103.40       741.6            0.1791   \n",
       "6  ...          27.66           153.20      1606.0            0.1442   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "5             0.5249           0.5355                0.1741          0.3985   \n",
       "6             0.2576           0.3784                0.1932          0.3063   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "5                  0.12440          NaN  \n",
       "6                  0.08368          NaN  \n",
       "\n",
       "[7 rows x 33 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#load the dataset from the source in df3\n",
    "df3 = pd.read_csv('/Users/praveenathegreat/Downloads/data.csv')\n",
    "df3.head(7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 33)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>842302</td>\n",
       "      <td>1</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>842517</td>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>84300903</td>\n",
       "      <td>1</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>84348301</td>\n",
       "      <td>1</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>84358402</td>\n",
       "      <td>1</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302          1        17.99         10.38          122.80     1001.0   \n",
       "1    842517          1        20.57         17.77          132.90     1326.0   \n",
       "2  84300903          1        19.69         21.25          130.00     1203.0   \n",
       "3  84348301          1        11.42         20.38           77.58      386.1   \n",
       "4  84358402          1        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replacing B and M with 0 and 1 \n",
    "df3[\"diagnosis\"] = df3[\"diagnosis\"].replace(\"B\", 0)\n",
    "df3[\"diagnosis\"] = df3[\"diagnosis\"].replace(\"M\", 1)\n",
    "df3.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.372583</td>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>...</td>\n",
       "      <td>16.269190</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.483918</td>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>...</td>\n",
       "      <td>4.833242</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>...</td>\n",
       "      <td>13.010000</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>...</td>\n",
       "      <td>14.970000</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>...</td>\n",
       "      <td>18.790000</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>...</td>\n",
       "      <td>36.040000</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        diagnosis  radius_mean  texture_mean  perimeter_mean    area_mean  \\\n",
       "count  569.000000   569.000000    569.000000      569.000000   569.000000   \n",
       "mean     0.372583    14.127292     19.289649       91.969033   654.889104   \n",
       "std      0.483918     3.524049      4.301036       24.298981   351.914129   \n",
       "min      0.000000     6.981000      9.710000       43.790000   143.500000   \n",
       "25%      0.000000    11.700000     16.170000       75.170000   420.300000   \n",
       "50%      0.000000    13.370000     18.840000       86.240000   551.100000   \n",
       "75%      1.000000    15.780000     21.800000      104.100000   782.700000   \n",
       "max      1.000000    28.110000     39.280000      188.500000  2501.000000   \n",
       "\n",
       "       smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "count       569.000000        569.000000      569.000000           569.000000   \n",
       "mean          0.096360          0.104341        0.088799             0.048919   \n",
       "std           0.014064          0.052813        0.079720             0.038803   \n",
       "min           0.052630          0.019380        0.000000             0.000000   \n",
       "25%           0.086370          0.064920        0.029560             0.020310   \n",
       "50%           0.095870          0.092630        0.061540             0.033500   \n",
       "75%           0.105300          0.130400        0.130700             0.074000   \n",
       "max           0.163400          0.345400        0.426800             0.201200   \n",
       "\n",
       "       symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "count     569.000000  ...    569.000000     569.000000       569.000000   \n",
       "mean        0.181162  ...     16.269190      25.677223       107.261213   \n",
       "std         0.027414  ...      4.833242       6.146258        33.602542   \n",
       "min         0.106000  ...      7.930000      12.020000        50.410000   \n",
       "25%         0.161900  ...     13.010000      21.080000        84.110000   \n",
       "50%         0.179200  ...     14.970000      25.410000        97.660000   \n",
       "75%         0.195700  ...     18.790000      29.720000       125.400000   \n",
       "max         0.304000  ...     36.040000      49.540000       251.200000   \n",
       "\n",
       "        area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "count   569.000000        569.000000         569.000000       569.000000   \n",
       "mean    880.583128          0.132369           0.254265         0.272188   \n",
       "std     569.356993          0.022832           0.157336         0.208624   \n",
       "min     185.200000          0.071170           0.027290         0.000000   \n",
       "25%     515.300000          0.116600           0.147200         0.114500   \n",
       "50%     686.500000          0.131300           0.211900         0.226700   \n",
       "75%    1084.000000          0.146000           0.339100         0.382900   \n",
       "max    4254.000000          0.222600           1.058000         1.252000   \n",
       "\n",
       "       concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "count            569.000000      569.000000               569.000000  \n",
       "mean               0.114606        0.290076                 0.083946  \n",
       "std                0.065732        0.061867                 0.018061  \n",
       "min                0.000000        0.156500                 0.055040  \n",
       "25%                0.064930        0.250400                 0.071460  \n",
       "50%                0.099930        0.282200                 0.080040  \n",
       "75%                0.161400        0.317900                 0.092080  \n",
       "max                0.291000        0.663800                 0.207500  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dropping all datas which are under Unnamed and column id since it does not have much significance \n",
    "\n",
    "df3.drop([\"id\", \"Unnamed: 32\"] ,axis=1, inplace=True)\n",
    "df3.describe() #All the columns - features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diagnosis                  0\n",
       "radius_mean                0\n",
       "texture_mean               0\n",
       "perimeter_mean             0\n",
       "area_mean                  0\n",
       "smoothness_mean            0\n",
       "compactness_mean           0\n",
       "concavity_mean             0\n",
       "concave points_mean        0\n",
       "symmetry_mean              0\n",
       "fractal_dimension_mean     0\n",
       "radius_se                  0\n",
       "texture_se                 0\n",
       "perimeter_se               0\n",
       "area_se                    0\n",
       "smoothness_se              0\n",
       "compactness_se             0\n",
       "concavity_se               0\n",
       "concave points_se          0\n",
       "symmetry_se                0\n",
       "fractal_dimension_se       0\n",
       "radius_worst               0\n",
       "texture_worst              0\n",
       "perimeter_worst            0\n",
       "area_worst                 0\n",
       "smoothness_worst           0\n",
       "compactness_worst          0\n",
       "concavity_worst            0\n",
       "concave points_worst       0\n",
       "symmetry_worst             0\n",
       "fractal_dimension_worst    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking if there are more null values or Unnamed datas\n",
    "df3.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 stands for Benign - which does not spread around body \n",
    "# 1 stands for Malignant -which spreads around body \n",
    "\n",
    "sns.pairplot(df3, hue='diagnosis', palette=\"dark\",kind=\"reg\", vars=[\"radius_mean\", \"texture_mean\", \"perimeter_mean\", \"area_mean\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Accuracy is :  0.956140350877193\n",
      "\n",
      "Confusion Matrix is: \n",
      " [[70  1]\n",
      " [ 4 39]]\n"
     ]
    }
   ],
   "source": [
    "'''Using SVM - Binary Classifier that can detect two classes B or M '''\n",
    "\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "X3 = df3.drop('diagnosis', axis=1) #Independent\n",
    "Y3 = df3.diagnosis #Dependent \n",
    "\n",
    "#Splitting the datset into 80:20 ratio \n",
    "Xtrain3, Xtest3, Ytrain3, Ytest3 = train_test_split(X3, Y3, test_size=0.2, random_state=42)\n",
    "\n",
    "# We now create a svm classifer with a linear kernel\n",
    "classifier = svm.SVC(kernel='linear')\n",
    "\n",
    "#Predict the testing Set \n",
    "classifier.fit(Xtrain3, Ytrain3)\n",
    "y_predict3 = classifier.predict(Xtest3)\n",
    "\n",
    "# We now score the models accuracy in identifying \n",
    "print(\"\\nModel Accuracy is : \", classifier.score(Xtest3, Ytest3))\n",
    "\n",
    "# Confusion_matrix\n",
    "#[[TrueNegative, TruePositive]\n",
    "# [FalseNegative, FalsePositive]]\n",
    "\n",
    "cm = confusion_matrix(Ytest3, y_predict3)\n",
    "print(\"\\nConfusion Matrix is: \\n\", cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Utilize .heatmap() method with cfm defined variable in previous cell that creates our \n",
    "# confusion matrix\n",
    "\n",
    "ax=plt.axes([2,2,1.2,1])\n",
    "sns.heatmap(pd.DataFrame(cm), annot=True, linewidth=1, ax=ax)\n",
    "plt.xlabel('0 for Benign and 1 for Maligant')\n",
    "plt.ylabel('0 for Benign and 1 for Maligant')\n",
    "plt.title(\"HEAT MAP\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97        71\n",
      "           1       0.97      0.91      0.94        43\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification report shows the precision, recall, f1-score(mean of precision and recall), support\n",
    "#This helps to measure the quality of predictions of how many were true and how many were false positives are specifically \n",
    "#Benign=0\n",
    "#Melignant=1\n",
    "print(classification_report(Ytest3, y_predict3))\n",
    "#Macro average is averaging the unweighted mean per label \n",
    "#weighted average is averaging the support weighted mean er label \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we used the Support Vector Machine as our classification algorithm, we proceed\n",
    "# to use its .fit() functionality, and prcoeed to perform the K-Fold Cross-Validation\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "    \n",
    "# We read the dataset using pandas \n",
    "df4 = pd.read_csv('/Users/praveenathegreat/Downloads/data.csv')\n",
    "df4[\"diagnosis\"] = df4[\"diagnosis\"].replace(\"B\", 0)\n",
    "df4[\"diagnosis\"] = df4[\"diagnosis\"].replace(\"M\", 1)\n",
    "df4.drop([\"id\", \"Unnamed: 32\"] ,axis=1, inplace=True)\n",
    "    \n",
    "X4= df4.drop('diagnosis', axis=1)\n",
    "Y4 = df4.diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K-Fold Cross-Validation - SVM Classifier Mean Square Error is: 0.04743107769423559\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import mean_absolute_error #needed to find the mean absolute error\n",
    "from sklearn.metrics import mean_squared_error #needed to find mean squared error\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import sklearn.linear_model as skl_lm\n",
    "from sklearn import metrics\n",
    "\n",
    "crossvalidation4 = KFold(n_splits=10, random_state=42)\n",
    "classifier4 = svm.SVC(kernel='linear')\n",
    "\n",
    "classifier4.fit(X4, Y4)\n",
    "for i in range(1):\n",
    "    poly=PolynomialFeatures(degree=1) #linear \n",
    "    X_current4 = poly.fit_transform(X4)\n",
    "    model = lm.fit(X_current4, Y4)\n",
    "    CVscores4 = cross_val_score(classifier4, X_current4, Y4, scoring=\"neg_mean_squared_error\", cv = crossvalidation4, n_jobs=1)\n",
    "    print(\"\\nK-Fold Cross-Validation - SVM Classifier Mean Square Error is: \" + str(np.mean(np.abs(CVscores4))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion \n",
    "\n",
    "\n",
    "This report was a real life analysis of the Breast Cancer Wisconsin Diagnostic patients, which makes it more surreal to work on it. The features of the dataset was created by the Dr. Wolberg who took samples from patients with solid breast masses and performed the cytological features based on MRI. Images taken from patients helped to find the mean value, standard error and extreme value of each feature. Therefore, each data was gathered from several patients who may or may not have breast cancer to further extend the data. There were a number of findings throughout the report. Out of total 569 patients, 62.7% were benign (absence of cancer cells) and 37.3% were cancer cells.\n",
    "\n",
    "   The increase of value for each feature correlated with the malignant tumors and where the features values were low were assumed to be benign cells, but there were some cases where the feature values were low, but turned out to be the cancer cells. With the help of linear regression and predicted models, I was able to find that even though patients had higher values, some can have lower values within certain features that could still turn out to be breast cancer. Apart from that major difference between, two were the radius distribution of malignancy, such that radius_mean, perimenter_mean, area_mean, concavity_mean and concave.points_mean were more skewed for the masses that were benign.\n",
    "   \n",
    "   Support Vector Machine helped to achieve the accuracy of 95.61%. Looking at the predictors, it proceeds to highlight the strong positive relationships, such that the classifier was able to detect 109 positives detections when predicting whether a mass was considered malignant cells, while only 5 were unable to be properly detected, which is pretty good. Even though it looks like it is overfitted model, the features itself were choosen from the filtered dataset where every feature had its own standard error and error rate looked upon. \n",
    "   \n",
    "   For linear regression, I had to go through 33 features one by one in order to showcase the features that made sense to the graph and also show the relations between each other. Apart from that I was intrigued to find the mean squared error of linear regression versus the quadratic least square regression values, therefore I did some research regarding the linear model and polynomial features and performed them on the model. The error rate values were very close to each other. I found that it was best to use the quadratic least square regression model if we are not performing a non-linear model.\n",
    "   \n",
    "   Some of the interesting facts, yet serious issues, that I found while working in this project was that one doesn’t have to be a specific gender, such as a female, that many refer to when hearing or thinking about having Breast Cancer. Even though that is the case, every 2 minutes one woman is diagnosed with Breast Cancer in the US, while only one in a thousand men will ever be diagnosed with Breast Cancer (less than one percent).\n",
    "   \n",
    "   Furthermore, to further extend this project, I would come up with even more features to include that could relate to Breast Cancer, and although this dataset already has 33 features, where only some of them are the only main datas, while others are just their mean and error rates. Finding more patients and collecting more datas values for these features would definitely help a lot. Apart from that, I would love to work on finding the MRI scans and train them so that next time we don't have to go through each image and record their data, therefore making the process a lot easier and simpler.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
